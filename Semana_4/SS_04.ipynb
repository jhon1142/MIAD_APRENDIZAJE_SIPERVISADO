{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div >\n",
    "<img src = \"figs/ans_banner_1920x200.png\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering II. Sesión Sincrónica.\n",
    "\n",
    "\n",
    "Tanto Clustering como PCA y SVD buscan simplificar los datos de forma no supervizada, pero sus mecanismos son diferentes:\n",
    "\n",
    "- PCA y SVD buscan encontrar una representación de baja dimensión de las observaciones que explique una buena fracción de la varianza;\n",
    "\n",
    "- Clustering busca encontrar subgrupos homogéneos entre las observaciones.\n",
    "\n",
    "\n",
    "El objetivo de este cuaderno es introducir los algoritmos que serán estudiados en la semana 4.\n",
    "\n",
    "**NO** es necesario editar el archivo o hacer una entrega. Los ejemplos contienen celdas con código ejecutable (`en gris`), que podrá modificar libremente. Esta puede ser una buena forma de aprender nuevas funcionalidades del *cuaderno*, o experimentar variaciones en los códigos de ejemplo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción \n",
    "\n",
    "## ¿Qué es el análisis de clusters? \n",
    "\n",
    "El análisis de clusters es una de las principales aplicaciones de los algoritmos de aprendizaje no supervisado. Este tipo de análisis se utiliza para juntar observaciones similares en grupos:\n",
    "\n",
    "\n",
    "\n",
    "<div style=\"max-width:500px\">\n",
    "<img src = \"figs/plot_clustering_notebook.png\" />\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "## Caveat\n",
    "\n",
    "Los métodos de clustering son exploratorios: se pueden utilizar para evaluar la calidad de los datos y generar hipótesis. \n",
    "\n",
    "Pero no importa lo que entre en el algoritmo de agrupamiento, los clusters salen. Esta es una situación clásica de \"basura que entra, basura que sale\". \n",
    "\n",
    "\n",
    "La conclusión es que la agrupación es buena si es útil para responder el problema en particular. Pero, esto es difícil de evaluar, a pesar de tener ciertas medidas de validez interna. Esto requiere que el usuario utilice su capacidad y discernimiento.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distancias\n",
    "\n",
    "Ejemplo 1: Calcular el parecido entre tres alumnos/as  a partir de sus notas usando la distancia euclideana:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "A= pd.DataFrame(np.array([[3,5,2,4], [1, 0, 3, 5], [9, 10, 2, 5]]))\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distancia Euclideana:\n",
    "\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "d_{02} = \\sqrt{(3−9)^2 +(5−10)^2 +(2−2)^2 +(4−5)^2} =7,87 \\\\\n",
    "d_{12} = \\sqrt{(1−9)^2 +(0−10)^2 +(3−2)^2 +(5−5)^2} =12,85  \\\\\n",
    "d_{01} = \\sqrt{(3−1)^2 +(5−0)^2  +(2−3)^2 +(4−5)^2} =5,57 \n",
    "\\end{equation}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "math.sqrt((3-9)**2 +(5-10)**2 +(2-2)**2 +(4-5)**2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.sqrt((1-9)**2 +(0-10)**2 +(3-2)**2 +(5-5)**2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.sqrt((3-1)**2 +(5-0)**2  +(2-3)**2 +(4-5)**2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance_matrix\n",
    "\n",
    "# Creamos la matriz de distancias escogiendo p = 2, el cual convierte \n",
    "# la distancia Minkowski en la distancia euclidiana\n",
    "pd.DataFrame(distance_matrix(A, A, p = 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Un problema de la distancia euclídiana, como medida de similaridad, es su dependencia de las diferentes escalas en que estén medidas las variables. \n",
    "\n",
    "- Escalas y rangos de variación diferentes pueden afectar al análisis de clusters.\n",
    "\n",
    "- Este problema se soluciona si en vez de calcular la distancia euclídea con puntuaciones directas se calcula con puntuaciones normalizadas. \n",
    "\n",
    "- Estandarizar las puntuaciones de los sujetos en las variables es uno de los procedimientos de normalización más frecuentes en análisis de datos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EJEMPLO 2. Supongamos que estamos interesados en agrupar a una muestra de 5 familias en base al número de hijos, al\n",
    "sueldo en euros al mes y al tamaño de la casa en metros cuadrados. La matriz de datos de la que partimos es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B= pd.DataFrame(np.array([[1,723,60], [1, 900, 60], [4,800,80], [0,1205,50], [2,600,65]]))\n",
    "B.columns = ['Hijos','Salario','Metros2']\n",
    "B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos como antes calcular las distancias entre los sujetos a partir de las puntuaciones directas o bien podemos calcularlas a partir de las variables estandarizadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(distance_matrix(B, B, p = 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puede observarse, las familias más parecidas son la familia primera y la tercera. Sin embargo, son familias que salvo en que tienen un salario similar son diferentes en el resto de las variables. Si por el contrario seleccionamos la opción estandarizar\n",
    "la matriz de distancias que obtenemos es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "\n",
    "pd.DataFrame(distance_matrix(scale(B), scale(B), p = 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Con las puntuaciones estandarizadas las familias más parecidas son la primera y la segunda. \n",
    "\n",
    "- Es evidente que los resultados de un análisis de clusters son distintos si se parte de matrices de similaridad o distancia que ordenen a los sujetos de manera distinta. \n",
    "\n",
    "- Es por ello que en caso de variables medidas en escalas distintas es necesario normalizar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EJEMPLO 3.  Supongamos que queremos agrupar a los sujetos de una muestra (N = 5) en\n",
    "función de su parecido en un conjunto de variables todas ellas dicotómicas: \n",
    "- Estado civil: soltero(1)-casado(0)\n",
    "- Situación laboral: ocupado(1)-desocupado(0)\n",
    "- Nivel de estudios: bajo(1)-alto(0)\n",
    "- Creencias religiosa: creyente(1)-no creyente(0)\n",
    "- Tendencia de voto en las últimas elecciones: izquierda(1)-derecha(0). \n",
    "\n",
    "La matriz de datos de la que partimos es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C= pd.DataFrame(np.array([[1,1,0,1,0], [1,1,1,0,0], [0,0,0,1,1], [0,0,0,0,1], [1,0,0,1,0]]))\n",
    "C.columns = ['Soltero','Ocupado','Baja_educacion', 'Creyente', \"Izquierda\"]\n",
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " La medida de distancia más utilizada en estos casos se conoce como distancia de coincidencia simple:\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "d_{ii'}=d(x_i,x_{i'})= I(x_i \\neq x_{i'})\n",
    "\\end{align}\n",
    "\n",
    "donde $I(.)$ es la función indicadora que toma valor 1 cuando las variables no coinciden, y 0 en caso contrario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C.iloc[:,0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import DistanceMetric\n",
    "\n",
    "DistanceMetric.get_metric('matching').pairwise(C.iloc[:,0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DistanceMetric.get_metric('matching').pairwise(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EJEMPLO 4. Supongamos que tenemos los siguientes datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Creamos un diccionario\n",
    "dictionary = {\"Edad\": [22, 25, 30, 38, 42, 47, 55, 62, 61, 90], \n",
    "              \"Genero\": [\"M\", \"M\", \"F\", \"F\", \"F\", \"M\", \"M\", \"M\", \"M\", \"M\"], \n",
    "              \"Estado_Civil\": [\"Soltero\", \"Soltero\", \"Soltero\", \"Casado\", \"Casado\", \"Soltero\", \"Casado\", \"Divorciado\", \"Casado\", \"Divorciado\"], \n",
    "              \"Salario\": [18000, 23000, 27000, 32000, 34000, 20000, 40000, 42000, 25000, 70000], \n",
    "              \"tiene_hijos\": [False, False, False, True, True, False, False, False, False, True], \n",
    "              \"Volumen_compras\": [\"Bajo\", \"Bajo\", \"Bajo\", \"Alto\", \"Alto\", \"Bajo\", \"Medio\", \"Medio\", \"Medio\", \"Bajo\"]}\n",
    "\n",
    "# Creamos un Pandas DataFrame \n",
    "D = pd.DataFrame.from_dict(dictionary)\n",
    "D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distancia de Gower\n",
    "\n",
    "- Para una característica numérica, la diferencia parcial entre dos clientes i y j es la resta entre sus valores en la característica específica (en valor absoluto) dividida por el rango total de la característica. El rango de salario es 52000 (70000–18000) mientras que el rango de edad es 68 (90–22). \n",
    "    Note, hay que tener en cuenta si existen outliers o valores atípicos. Un valor erróneo extremadamente grande o pequeño afectaría directamente el rango y, por lo tanto, las diferencias en esa característica, distorsionando su importancia.\n",
    "\n",
    "-    Para una característica categórica, la diferencia parcial entre dos clientes es uno cuando ambos clientes tienen un valor diferente para esta característica. Cero en caso contrario.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D.iloc[0:2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D.iloc[:,0].max()-D.iloc[:,0].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(22-25)/68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D.iloc[:,3].max()-D.iloc[:,3].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(18000-23000)/52000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La Disimilitud de Gower entre ambos clientes es el promedio de disimilitudes parciales a lo largo de las diferentes características: \n",
    "\n",
    "\\begin{align}\n",
    "\\frac{(0,044118 + 0 + 0 + 0,096154 + 0 + 0)}{ 6} = 0,023379. \n",
    "\\end{align}\n",
    "\n",
    "Como el valor es cercano a cero, podemos decir que ambos clientes son muy similares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gower\n",
    "\n",
    "distance_matrix = gower.gower_matrix(D)\n",
    "pd.DataFrame(distance_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Jerárquico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enlace completo (complete linkage - CL)\n",
    "   \n",
    "   El enlace completo o técnica del vecino más lejano, es lo opuesto al enlace simple y combina los clusters encontrando la distancia máxima entre las observaciones del cluster $G$ y las observaciones del cluster $H$:\n",
    "\n",
    "   \\begin{align}\n",
    "     d_{CL}(G, H)= max_{i\\in G,\\ i'\\in H} d_{ii'} \n",
    "   \\end{align}\n",
    "\n",
    "   En otras palabras, funciona combinando clusters en función de los puntos más alejados entre los dos clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ejemplo:\n",
    "\n",
    "|   | 1  | 2  | 3 | 4 | 5 |\n",
    "|---|----|----|---|---|---|\n",
    "| **1** | 0  |    |   |   |   |\n",
    "| **2** | 9  | 0  |   |   |   |\n",
    "| **3** | 3  | 7  | 0 |   |   |\n",
    "| **4** | 6  | 5  | 9 | 0 |   |\n",
    "| **5** | 11 | 10 | 2 | 8 | 0 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN\n",
    "\n",
    "- DBSCAN (por su nombre en inglés *Density-based spatial clustering of applications with noise*) agrupa los datos en función de las densidades de las observaciones, mientras maneja el ruido de manera eficiente.  \n",
    "\n",
    "\n",
    "- DBSCAN  incorpora  la noción de densidad. Si hay grupos de puntos de datos que existen en el mismo vencindario, estos se pueden ver como miembros del mismo cluster.\n",
    "\n",
    "\n",
    "- Pero para hacerlo dependende de principalmente de 2 parámetros: *eps* y *min_samples*.\n",
    "\n",
    "\n",
    "- **Formalmente** *Cluster.* Sea $D$ conjunto de puntos. El cluster $C$ con respecto a `eps` y `min_samples` es un subconjunto no vacío de $D$ que satisface las siguientes condiciones:\n",
    "    1. $\\forall\\ p, q:$ if $p\\in C$ y $q$ es alcanzable por densidad por $p$ con respecto a `eps` y `min_samples` dados, entonces $q \\in C$.\n",
    "    2. $\\forall\\ p, q \\in C:$ $p$ está conectado por densidad con $q$ con respecto al `eps` y `min_samples` dados.\n",
    "  \n",
    "  - *Ruido.* Sean $C_1, \\cdots, C_k$ los clústeres conformados a partir de los puntos  $D$ usando los parámetros `eps` y `min_samples` fijos. Definimos como ruido a todos los puntos que no pertenecen a ningún cluster pero están presentes en $D$:\n",
    "\n",
    "$$ruido = \\{p\\in D | \\forall i: p \\notin C_i \\}$$\n",
    "\n",
    "Veamos como funciona:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"max-width:400px\">\n",
    "    <img src = \"figs/DBSCAN_tutorial.gif\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering para \"Marketing Data Science\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para que un negocio prospere, es fundamental atraer nuevos clientes, al mismo tiempo que reteniendo efectivamente los actuales. \n",
    "\n",
    "El análisis de clusters facilita identificar grupos homogéneos permitiendo realizar estrategias que permiten captar oportunidades que los análisis tradicionales a menudo no son capaces.\n",
    "\n",
    "En esta tarea es importante que los segmentos identificados mediante el análisis de clusters deben ser tanto reconocibles como accesibles. Esto permite a los gerentes de marketing personalizar productos y mensajes de manera eficaz, optimizando las campañas de marketing para alcanzar de manera efectiva a cada grupo.\n",
    "\n",
    "Para ello es crucial elegir variables que no solo segmenten efectivamente el mercado, sino que también sean fáciles de medir y estén ampliamente disponibles. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Marketing Bancario\"\n",
    "\n",
    "Esta base de datos proviene del UCI Machine Learning Repository y fue utilizada en estudios sobre campañas de marketing directo, particularmente en la promoción de depósitos a plazo fijo.\n",
    "\n",
    "Los datos fueron recopilados de campañas de marketing telefónico de un banco en Portugal. El objetivo principal era predecir si un cliente suscribiría o no un depósito a plazo después de ser contactado. Pero nosotros la utilizaremos para ver si podemos identificar segmentos de clientes potenciales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las librerías\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# leer los datos\n",
    "bank = pd.read_csv('data/bank_es.csv', sep = ',')\n",
    "\n",
    "# Ver las primeras observaciones\n",
    "bank.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Variables Demográficas**:\n",
    "     - `edad`: Edad del cliente.\n",
    "     - `trabajo`: Tipo de empleo del cliente (e.g., \"admin.\", \"blue-collar\", \"technician\").\n",
    "     - `estado civil`: Estado civil del cliente (e.g., \"single\", \"married\", \"divorced\").\n",
    "     - `educación`: Nivel educativo del cliente (e.g., \"primary\", \"secondary\", \"tertiary\").\n",
    "\n",
    "2. **Historial Bancario**:\n",
    "     - `impago`: Si el cliente tiene crédito en mora (binaria: \"sí\", \"no\").\n",
    "     - `saldo`: Saldo promedio en la cuenta bancaria del cliente.\n",
    "     - `hipoteca`: Si el cliente tiene un préstamo hipotecario (binaria: \"sí\", \"no\").\n",
    "     - `préstamo`: Si el cliente tiene un préstamo personal (binaria: \"sí\", \"no\").\n",
    "     - `contactos_campaña`: Número de contactos realizados durante esta campaña.\n",
    "     - `dias_ultimo_contacto`: Días transcurridos desde que el cliente fue contactado por última vez en una campaña anterior.\n",
    "     - `contactos_previos`: Número de contactos realizados antes de esta campaña.\n",
    "     - `resultado de la campaña previa`: Resultado de la campaña anterior (e.g., \"success\", \"failure\").\n",
    "\n",
    "3. **Información del Contacto**:\n",
    "     - `contacto`: Tipo de contacto de la comunicación (e.g., \"cellular\", \"telephone\").\n",
    "     - `mes`: Último mes de contacto en la campaña.\n",
    "     - `día`: Último día del mes en que se realizó el contacto.\n",
    "     - `duración`: Duración de la última llamada en segundos.\n",
    "\n",
    "4. **Variable de Resultado**:\n",
    "     - `respuesta`: Variable binaria objetivo que indica si el cliente suscribió o no un depósito a plazo (binaria: \"sí\", \"no\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos preocuparan principalmente aquellos individuos sin contactos previos a esta campaña."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sin contacto previo\n",
    "bank = bank[bank['contactos_previos'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejercicio  nos centramos principalmente en las variables demográficas (`edad`, `trabajo`, `estado civil`, `educación`) y algunas relacionadas a componentes bancarios (`hipoteca`, `préstamo`) que son accesibles para todos los clientes, incluidas aquellas personas que aún no tienen un historial de transacciones con el banco.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a preparar los datos para el análisis de clustering, se transforman las variables categóricas en variables binarias y se estandarizan las variables numéricas, lo que facilita la identificación de segmentos de clientes similares.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generar una nueva variable empleo_cuello_blanco que son los que tienen trabajos administrativos, gerenciales, emprendedores y autonomos\n",
    "bank['empleo_cuello_blanco'] = bank['trabajo'].apply(lambda x: 1 if x in ['administrativo.', 'gerente', 'emprendedor', 'autonomo'] else 0)\n",
    "\n",
    "# generar tabla de contingencia trabajo vs empleo_cuello_blanco\n",
    "pd.crosstab(index = bank['trabajo'], columns = bank['empleo_cuello_blanco'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generar una nueva variable empleo_cuello_azul que son los que tienen trabajos obreros, ama de casa, servicios, tecnico \n",
    "bank['empleo_cuello_azul'] = bank['trabajo'].apply(lambda x: 1 if x in ['obrero', 'ama_de_casa', 'servicios', 'tecnico'] else 0)\n",
    "\n",
    "# generar tabla de contingencia trabajo vs empleo_cuello_blanco\n",
    "pd.crosstab(index = bank['trabajo'], columns = bank['empleo_cuello_azul'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generar dummies estado_civil en la base de datos\n",
    "bank = pd.get_dummies(bank, columns = ['estado_civil'], drop_first = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generar dummies educacion en la base de datos\n",
    "bank = pd.get_dummies(bank, columns = ['educacion'], drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reemplazar hipoteca y prestamo \"no\" por 0 y \"si\" por 1\n",
    "bank['hipoteca'] = bank['hipoteca'].apply(lambda x: 0 if x == 'no' else 1)\n",
    "bank['prestamo'] = bank['prestamo'].apply(lambda x: 0 if x == 'no' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# retener `edad`, `trabajo`, `estado civil`, `educación`, `hipoteca`, `préstamo`\n",
    "bank = bank[['edad', 'empleo_cuello_blanco', 'empleo_cuello_azul', 'estado_civil_soltero', 'estado_civil_divorciado', 'educacion_primaria', 'educacion_secundaria', 'educacion_terciaria', 'hipoteca', 'prestamo']]\n",
    "bank.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Jerárquico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos  las librerías\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "from scipy.cluster.hierarchy import dendrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "distances1 = linkage(scale(bank), method='complete', metric=\"euclidean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "d = dendrogram(distances1, show_leaf_counts=True, leaf_font_size=6, ax=ax,labels=bank.index)\n",
    "ax.set_xlabel('Observaciones', fontsize=6)\n",
    "ax.set_yticks(np.arange(0, 10, 1))\n",
    "ax.set_ylabel('Distancia', fontsize=14)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances2 = linkage(bank, method='complete', metric=\"euclidean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "d = dendrogram(distances2, show_leaf_counts=True, leaf_font_size=6, ax=ax,labels=bank.index)\n",
    "ax.set_xlabel('Observaciones', fontsize=6)\n",
    "ax.set_yticks(np.arange(0, 20, 1))\n",
    "ax.set_ylabel('Distancia', fontsize=14)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances3 = linkage(bank, method='complete', metric=\"cityblock\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "d = dendrogram(distances3, show_leaf_counts=True, leaf_font_size=14, ax=ax,labels=bank.index)\n",
    "ax.set_xlabel('Observaciones', fontsize=14)\n",
    "ax.set_yticks(np.arange(0, 20,1))\n",
    "ax.set_ylabel('Distancia', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "neigh = NearestNeighbors(n_neighbors = 4)\n",
    "nbrs = neigh.fit(bank)\n",
    "distancias, indices = nbrs.kneighbors(bank)\n",
    "distancias = np.sort(distancias.flatten())\n",
    "fig=plt.figure(figsize=(10,8), dpi= 100, facecolor='w', edgecolor='k')\n",
    "plt.axhline(y = 0.5, color = 'r', linestyle = '--')\n",
    "plt.plot(distancias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kneed import KneeLocator\n",
    "\n",
    "i = np.arange(len(distancias))\n",
    "knee = KneeLocator(i, distancias, S=1, curve='convex', direction='increasing', interp_method='polynomial')\n",
    "\n",
    "print(distancias[knee.knee])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DBSCAN(eps=1, min_samples=30)\n",
    "clusters=db.fit_predict(bank)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank['cluster_dbscan'] = clusters\n",
    "bank.groupby('cluster_dbscan').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referencias\n",
    "\n",
    "- Leskovec, J., Rajaraman, A., & Ullman, J. D. (2020). Mining of massive data sets. Cambridge university press.\n",
    "- Sheehan, D. (2022). https://dashee87.github.io/data%20science/general/Clustering-with-Scikit-with-GIFs/\n",
    "- Waggoner, P. Unsupervised Machine Learning for Clustering in Political and Social Research. Mimeo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Información de Sesión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import session_info\n",
    "\n",
    "session_info.show(html=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
